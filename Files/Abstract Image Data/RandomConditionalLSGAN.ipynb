{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5UV5Im06Qg7"
   },
   "source": [
    "## Environment set up and import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.368356Z",
     "iopub.status.busy": "2022-08-22T07:31:31.367663Z",
     "iopub.status.idle": "2022-08-22T07:31:31.373571Z",
     "shell.execute_reply": "2022-08-22T07:31:31.372424Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.368318Z"
    },
    "id": "b-0LJOu1Jumr",
    "outputId": "b3b46c35-a4ae-4b55-d3bf-8f0c17f62e71"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.378667Z",
     "iopub.status.busy": "2022-08-22T07:31:31.377798Z",
     "iopub.status.idle": "2022-08-22T07:31:31.388967Z",
     "shell.execute_reply": "2022-08-22T07:31:31.387916Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.378631Z"
    },
    "id": "izI8Tcx5Sswy",
    "outputId": "f5a385e6-6314-42b8-d293-9cc1a0cd9f45"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "with tf.device(device_name):\n",
    "  print(device_name.split(\":\")[1],\" running . . . \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.391903Z",
     "iopub.status.busy": "2022-08-22T07:31:31.391086Z",
     "iopub.status.idle": "2022-08-22T07:31:31.411772Z",
     "shell.execute_reply": "2022-08-22T07:31:31.410532Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.391861Z"
    },
    "id": "BZNKon484KfJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.418849Z",
     "iopub.status.busy": "2022-08-22T07:31:31.418574Z",
     "iopub.status.idle": "2022-08-22T07:31:31.426744Z",
     "shell.execute_reply": "2022-08-22T07:31:31.425504Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.418824Z"
    },
    "id": "U7Vkit2dTCvS"
   },
   "outputs": [],
   "source": [
    "import os, keras, numpy,tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V1zVhkQ6V1P"
   },
   "source": [
    "## **Discriminator** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.428809Z",
     "iopub.status.busy": "2022-08-22T07:31:31.428325Z",
     "iopub.status.idle": "2022-08-22T07:31:31.580448Z",
     "shell.execute_reply": "2022-08-22T07:31:31.579338Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.428774Z"
    },
    "id": "13b25edNTGV5",
    "outputId": "65ae35d0-30a1-427d-a32a-41dac734bde6"
   },
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(128,128,3),n_classes=5):\n",
    "\n",
    "    # input level\n",
    "    label_layer_1 = Input(shape=(1,), name = \"input_label\")\n",
    "    label_layer_2 = Embedding(n_classes, 200)(label_layer_1)\n",
    "    label_layer_3 = Dense(in_shape[0] * in_shape[1])(label_layer_2)\n",
    "    label_layer_4 = Reshape((in_shape[0], in_shape[1], 1))(label_layer_3)\n",
    "    # (128, 128, 1)\n",
    "\n",
    "    # input image\n",
    "    input_image = Input(shape=in_shape, name = \"input_image\")\n",
    "    # (128, 128, 3)\n",
    "\n",
    "    concat_layer = Concatenate()([input_image, label_layer_4])\n",
    "    # (128, 128, 4)\n",
    "\n",
    "    conv2d_layer_1 = Conv2D(filters = 16, kernel_size = (3,3), strides = (2,2), padding='same')(concat_layer)\n",
    "    conv2d_layer_1 = LeakyReLU(alpha=0.3)(conv2d_layer_1)\n",
    "    # (64, 64, 16)\n",
    "\n",
    "    conv2d_layer_2 = Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_1)\n",
    "    conv2d_layer_2 = LeakyReLU(alpha=0.3)(conv2d_layer_2)\n",
    "    # (32, 32, 32)\n",
    "\n",
    "    label_layer_3_1 = Dense(32 * 32)(label_layer_2)\n",
    "    label_layer_4_1 = Reshape((32, 32, 1))(label_layer_3_1)\n",
    "    # (32, 32, 1)\n",
    "\n",
    "    concat_layer_1 = Concatenate()([conv2d_layer_2, label_layer_4_1])\n",
    "    # (32, 32, 33)\n",
    "\n",
    "    conv2d_layer_3 = Conv2D(filters = 64, kernel_size = (3,3),  strides = (2,2), padding = 'same')(concat_layer_1)\n",
    "    conv2d_layer_3 = LeakyReLU(alpha=0.3)(conv2d_layer_3)\n",
    "    # (16, 16, 64)\n",
    "\n",
    "    conv2d_layer_4 = Conv2D(filters = 128, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_3)\n",
    "    conv2d_layer_4 = LeakyReLU(alpha=0.3)(conv2d_layer_4)\n",
    "    # (8, 8, 128)\n",
    "\n",
    "    conv2d_layer_5 = Conv2D(filters = 256, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_4)\n",
    "    conv2d_layer_5 = LeakyReLU(alpha=0.3)(conv2d_layer_5)\n",
    "    # (4, 4, 256)\n",
    "\n",
    "    flatten_layer = Flatten()(conv2d_layer_5)\n",
    "    # (4 * 4 * 256)\n",
    "\n",
    "    dropout_layer = Dropout(rate=0.4)(flatten_layer)\n",
    "    # (4 * 4 * 256)\n",
    "\n",
    "    dense_layer = Dense(128 * 8 * 2, activation='relu')(dropout_layer)\n",
    "    # (8 * 128 * 2)\n",
    "\n",
    "    # final layer\n",
    "    output_layer = Dense(1, activation='linear')(dense_layer)\n",
    "    # (1,)\n",
    "\n",
    "    model = Model([input_image,label_layer_1], output_layer)\n",
    "\n",
    "    opt = Adam(learning_rate= 3e-4, beta_1=0.5)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "a = define_discriminator()\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.583675Z",
     "iopub.status.busy": "2022-08-22T07:31:31.583213Z",
     "iopub.status.idle": "2022-08-22T07:31:31.807806Z",
     "shell.execute_reply": "2022-08-22T07:31:31.806570Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.583638Z"
    },
    "id": "f4D-H0p65xNd",
    "outputId": "583334bb-5aed-4d08-ecc7-8c98b89c1aa3"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator model\n",
    "tf.keras.utils.plot_model(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As6FQBwl6jjG"
   },
   "source": [
    "## **Generator** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:31.810777Z",
     "iopub.status.busy": "2022-08-22T07:31:31.810057Z",
     "iopub.status.idle": "2022-08-22T07:31:32.044525Z",
     "shell.execute_reply": "2022-08-22T07:31:32.042616Z",
     "shell.execute_reply.started": "2022-08-22T07:31:31.810735Z"
    },
    "id": "0GfMsg2WTJUK",
    "outputId": "aee90d8c-da8f-43ce-ad41-4d0883177e6d"
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim = 100, n_classes = 5):\n",
    "\n",
    "    # input level\n",
    "    label_layer_1 = Input(shape=(1,), name = \"input_label\")\n",
    "    label_layer_2 = Embedding(n_classes, 200)(label_layer_1)\n",
    "    label_layer_3 = Dense(8 * 8)(label_layer_2)\n",
    "    label_layer_4 = Reshape((8, 8, 1))(label_layer_3)\n",
    "    # (8, 8, 1)\n",
    "\n",
    "    # latent input\n",
    "    latent_layer = Input(shape=(latent_dim,), name = \"input_latent\")\n",
    "\n",
    "    layer_2 = Dense(128 * 8 * 8)(latent_layer)\n",
    "    layer_2 = Activation(\"relu\")(layer_2)\n",
    "    layer_2 = Reshape((8, 8, 128))(layer_2)\n",
    "    layer_2_1 = BatchNormalization(momentum = 0.8)(layer_2)\n",
    "    # (8, 8, 128)\n",
    "\n",
    "\n",
    "    concat_layer_1 = Concatenate()([layer_2_1, label_layer_4])\n",
    "    # (8, 8, 129)\n",
    "\n",
    "    layer_3 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(concat_layer_1)\n",
    "    layer_3 = Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer = initializers.RandomNormal(0,0.8))(layer_3)\n",
    "    layer_3 = BatchNormalization(momentum = 0.8)(layer_3)\n",
    "    layer_3 = LeakyReLU(alpha=0.4)(layer_3)\n",
    "    # (16, 16, 64)\n",
    "\n",
    "    layer_4 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(layer_3)\n",
    "    layer_4 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_4)\n",
    "    layer_4 = BatchNormalization(momentum = 0.8)(layer_4)\n",
    "    layer_4 = LeakyReLU(alpha=0.4)(layer_4)\n",
    "    # (32, 32, 64)\n",
    "\n",
    "    # label_layer_2_1 = Embedding(n_classes, 100)(label_layer_1)\n",
    "    label_layer_3_1 = Dense(32 * 32)(label_layer_2)\n",
    "    label_layer_4_1 = Reshape((32, 32, 1))(label_layer_3_1)\n",
    "    # label_layer_5_1 = BatchNormalization(momentum = 0.8)(label_layer_4_1)\n",
    "    # (32, 32, 1)\n",
    "\n",
    "    concat_layer_2 = Concatenate()([layer_4, label_layer_4_1])\n",
    "    # (32, 32, 65)\n",
    "\n",
    "\n",
    "    layer_5 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(concat_layer_2)\n",
    "    layer_5 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_5)\n",
    "    layer_5 = BatchNormalization(momentum = 0.8)(layer_5)\n",
    "    layer_5 = LeakyReLU(alpha=0.4)(layer_5)\n",
    "    # (64, 64, 64)\n",
    "\n",
    "    layer_6 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(layer_5)\n",
    "    layer_6 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_6)\n",
    "    layer_6 = BatchNormalization(momentum = 0.8)(layer_6)\n",
    "    layer_6 = LeakyReLU(alpha=0.4)(layer_6)\n",
    "    # (128, 128, 64)\n",
    "\n",
    "    # final layer\n",
    "    output_layer = Conv2D(filters = 3, kernel_size = (3,3), strides=(1,1), activation='tanh', padding='same')(layer_6)\n",
    "\n",
    "    model = Model([latent_layer,label_layer_1], output_layer)\n",
    "    return model\n",
    "\n",
    "b = define_generator(512)\n",
    "b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.047166Z",
     "iopub.status.busy": "2022-08-22T07:31:32.046123Z",
     "iopub.status.idle": "2022-08-22T07:31:32.377864Z",
     "shell.execute_reply": "2022-08-22T07:31:32.376557Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.047127Z"
    },
    "id": "uOab7yJz55vE",
    "outputId": "64038344-f57a-4e25-9394-117274f25d39"
   },
   "outputs": [],
   "source": [
    "# plot the generator model\n",
    "tf.keras.utils.plot_model(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K74ltFTw63K_"
   },
   "source": [
    "## **Combine** or **GAN** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.380656Z",
     "iopub.status.busy": "2022-08-22T07:31:32.379999Z",
     "iopub.status.idle": "2022-08-22T07:31:32.479971Z",
     "shell.execute_reply": "2022-08-22T07:31:32.478864Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.380615Z"
    },
    "id": "KmspouGiTLhn",
    "outputId": "d8779196-27b4-45d9-ab99-ab6ed672a195"
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "\n",
    "  d_model.trainable = False\n",
    "\n",
    "  g_latent, g_label = g_model.input\n",
    "  g_output = g_model.output\n",
    "\n",
    "  d_output = d_model([g_output,g_label])\n",
    "\n",
    "  model = Model([g_latent, g_label], d_output)\n",
    "\n",
    "  opt = Adam(learning_rate= 3e-4, beta_1=0.5)\n",
    "  model.compile(loss='mse', optimizer=opt,  metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "c = define_gan(b, a)\n",
    "c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.482449Z",
     "iopub.status.busy": "2022-08-22T07:31:32.481941Z",
     "iopub.status.idle": "2022-08-22T07:31:32.831509Z",
     "shell.execute_reply": "2022-08-22T07:31:32.830434Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.482409Z"
    },
    "id": "Zuaon8Y75-Ps",
    "outputId": "6d357702-3467-4f56-de0b-3dd86ff54280"
   },
   "outputs": [],
   "source": [
    "# plot GAN model\n",
    "tf.keras.utils.plot_model(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgckUXEo7DxG"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.834384Z",
     "iopub.status.busy": "2022-08-22T07:31:32.833640Z",
     "iopub.status.idle": "2022-08-22T07:31:32.841295Z",
     "shell.execute_reply": "2022-08-22T07:31:32.840263Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.834342Z"
    },
    "id": "VhzajBRw4wxU"
   },
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "  # load dataset\n",
    "  data = np.load(\"../input/lsganabstract/Abstract_128_combo.npz\")\n",
    "  data = data['a']\n",
    "  data = np.array(data)\n",
    "  X = data.astype('float32')\n",
    "  # scale from [0,255] to [-1,1]\n",
    "  X = (X - 127.5) / 127.5\n",
    "  return X\n",
    "# k = load_real_samples()\n",
    "# print(\"image: \",k.shape)\n",
    "# print(\"\\nshape/size of the first 16 data: \",k[:16].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDrk7zuwJoN9"
   },
   "source": [
    "## Plot data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.846768Z",
     "iopub.status.busy": "2022-08-22T07:31:32.846472Z",
     "iopub.status.idle": "2022-08-22T07:31:32.854682Z",
     "shell.execute_reply": "2022-08-22T07:31:32.853539Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.846743Z"
    },
    "id": "ADMcakmWTN60"
   },
   "outputs": [],
   "source": [
    "def save_plot(x_input,n=4):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.imshow(x_input[i,:,:,:])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "# plot data\n",
    "# save_plot(k[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcmHiLEK8HQP"
   },
   "source": [
    "## Generate real sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.856743Z",
     "iopub.status.busy": "2022-08-22T07:31:32.856361Z",
     "iopub.status.idle": "2022-08-22T07:31:32.863980Z",
     "shell.execute_reply": "2022-08-22T07:31:32.862990Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.856710Z"
    },
    "id": "uR1tkpInTQq4"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "\timages = dataset\n",
    "\tix = randint(0, images.shape[0], n_samples)\n",
    "\tX = images[ix]\n",
    "\tz = np.random.randint(0,5,size=(n_samples))\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn [X,z], y\n",
    "# d = generate_real_samples(k, 32)\n",
    "# print(\"Generate real data as a batch randomly: \",d[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MQHAJ0P8kPF"
   },
   "source": [
    "## Generate latent point function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.866235Z",
     "iopub.status.busy": "2022-08-22T07:31:32.865427Z",
     "iopub.status.idle": "2022-08-22T07:31:32.875727Z",
     "shell.execute_reply": "2022-08-22T07:31:32.874638Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.866200Z"
    },
    "id": "Fv9g2IJXTSpw"
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "  x_input = randn(latent_dim * n_samples)\n",
    "  z_input = x_input.reshape(n_samples, latent_dim)\n",
    "  z = np.random.randint(0,5,size=(n_samples))\n",
    "  return [z_input,z]\n",
    "# p = generate_latent_points(512, 32)\n",
    "# print(\"Generate latent point(with label) as a batch: \",p[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IAEwd9V9GsR"
   },
   "source": [
    "## Generate Fake samples of image with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.877697Z",
     "iopub.status.busy": "2022-08-22T07:31:32.877211Z",
     "iopub.status.idle": "2022-08-22T07:31:32.885400Z",
     "shell.execute_reply": "2022-08-22T07:31:32.884344Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.877662Z"
    },
    "id": "qTcS-0Ou42nA"
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\tz_input,z = generate_latent_points(latent_dim, n_samples)\n",
    "\timages = generator.predict([z_input,z])\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn [images, z], y\n",
    "# with tf.device(device_name):\n",
    "\t# kh = generate_fake_samples(b, 512, 32)\n",
    "\t# print(\"shape of the generated images: \",kh[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Pb6LIHF9mZM"
   },
   "source": [
    "## Summarize the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.887578Z",
     "iopub.status.busy": "2022-08-22T07:31:32.887163Z",
     "iopub.status.idle": "2022-08-22T07:31:32.893843Z",
     "shell.execute_reply": "2022-08-22T07:31:32.892782Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.887543Z"
    },
    "id": "7c0-Luo746t2"
   },
   "outputs": [],
   "source": [
    "def summarize_the_model(generator,latent_dim = 100):\n",
    "    latent_points = generate_latent_points(latent_dim= latent_dim, n_samples= 16)\n",
    "    X  = generator.predict(latent_points)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    save_plot(X, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.896830Z",
     "iopub.status.busy": "2022-08-22T07:31:32.895155Z",
     "iopub.status.idle": "2022-08-22T07:31:32.905162Z",
     "shell.execute_reply": "2022-08-22T07:31:32.904122Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.896801Z"
    },
    "id": "AgkghuoxJMqv"
   },
   "outputs": [],
   "source": [
    "def save_figure(generator,a,latent_dim = 512,n=4):\n",
    "    latent_points, labels = generate_latent_points(latent_dim= latent_dim, n_samples= 16)\n",
    "    X  = generator.predict([latent_points, labels])\n",
    "    X = (X + 1) / 2.0\n",
    "    # plt.title(\"Epoch_\"+str(a+1),loc = \"center\")\n",
    "    plt.figure(figsize=(15,7))\n",
    "    for j in range(n*n):\n",
    "        plt.subplot(n, n, j+1)\n",
    "        plt.imshow(X[j,:,:,:])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Epoch_\"+str(a+1))\n",
    "    plt.savefig(\"/content/drive/MyDrive/GAN_New_Approch/LSGAN/Epoch_\"+str(a+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWKEC8MA9tGE"
   },
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.907159Z",
     "iopub.status.busy": "2022-08-22T07:31:32.906639Z",
     "iopub.status.idle": "2022-08-22T07:31:32.920861Z",
     "shell.execute_reply": "2022-08-22T07:31:32.919868Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.907124Z"
    },
    "id": "VtrEiQruSiOE"
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim= 100, n_epochs=3, n_batch=128):\n",
    "\n",
    "  print(\"No. of epoch: \",n_epochs)\n",
    "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "  print(\"batch per epoch: \", bat_per_epo)\n",
    "  print(\"full batch: \",n_batch)\n",
    "  half_batch = int(n_batch / 2)\n",
    "  print(\"half batch: \", half_batch,'\\n')\n",
    "  print(\"*\"*50,'\\n\\n')\n",
    "\n",
    "  d_loss_real_array,d_loss_fake_array =[],[]\n",
    "  g_loss_array = []\n",
    "  for i in range(n_epochs):\n",
    "    d_loss_r,d_loss_f = 0.0,0.0\n",
    "    g_loss = 0.0\n",
    "    \n",
    "    for j in range(bat_per_epo):\n",
    "\n",
    "      [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "      d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "      d_loss_r += ( d_loss1 / half_batch)\n",
    "      # print(\"real_loss\")\n",
    "\n",
    "      [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "      d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "      d_loss_f += ( d_loss2 / half_batch )\n",
    "      # print(\"fake_loss\")\n",
    "\n",
    "      [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "      y_gan = ones((n_batch, 1))\n",
    "      g_loss1,_ = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "      g_loss += ( g_loss1 / n_batch )\n",
    "\n",
    "    d_loss_real_array.append(d_loss_r / bat_per_epo)\n",
    "    d_loss_fake_array.append(d_loss_f / bat_per_epo)\n",
    "    g_loss_array.append(g_loss / bat_per_epo)\n",
    "\n",
    "    print('epoch -> [%d/%d], discriminator_loss_for_real_data = %f, discriminator_loss_for_fake_data = %f, generator_loss = %f' %(i+1, n_epochs, d_loss_r/bat_per_epo, d_loss_f/bat_per_epo, g_loss/bat_per_epo))\n",
    "    if((i+1)%5==0):\n",
    "        summarize_the_model(g_model,latent_dim)\n",
    "        save_figure(g_model,i,latent_dim = 512,n=4)\n",
    "    g_model.save(\"generator_model_2.h5\")\n",
    "    np.savez_compressed('loss_record_2.npz', a=d_loss_real_array, b=d_loss_fake_array, c=g_loss_array)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "  return d_loss_real_array, d_loss_fake_array, g_loss_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsaXTk2x987F"
   },
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T07:31:32.923044Z",
     "iopub.status.busy": "2022-08-22T07:31:32.922312Z",
     "iopub.status.idle": "2022-08-22T11:38:52.388210Z",
     "shell.execute_reply": "2022-08-22T11:38:52.387177Z",
     "shell.execute_reply.started": "2022-08-22T07:31:32.923010Z"
    },
    "id": "gMtQt5LfTY82",
    "outputId": "89a56869-6709-4c92-8d08-91461608a26e"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "  latent_dim = 512\n",
    "  n_epochs = 250\n",
    "  n_batch = 32\n",
    "  d_model = define_discriminator()\n",
    "  g_model = define_generator(latent_dim)\n",
    "  gan_model = define_gan(g_model, d_model)\n",
    "  dataset = load_real_samples()\n",
    "  print('\\nREADY TO GO !!!\\n')\n",
    "  \n",
    "  d_loss_real_array, d_loss_fake_array, g_loss_array = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWkVxCBlxi3p"
   },
   "source": [
    "## Plot Loss Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:29.408672Z",
     "iopub.status.busy": "2022-08-22T12:01:29.408263Z",
     "iopub.status.idle": "2022-08-22T12:01:29.413788Z",
     "shell.execute_reply": "2022-08-22T12:01:29.412600Z",
     "shell.execute_reply.started": "2022-08-22T12:01:29.408640Z"
    },
    "id": "fokaLjhG3uCs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:30.833298Z",
     "iopub.status.busy": "2022-08-22T12:01:30.832853Z",
     "iopub.status.idle": "2022-08-22T12:01:30.839013Z",
     "shell.execute_reply": "2022-08-22T12:01:30.837871Z",
     "shell.execute_reply.started": "2022-08-22T12:01:30.833260Z"
    },
    "id": "zw228YsVuN0O"
   },
   "outputs": [],
   "source": [
    "d_loss = np.array([(i+j) for i,j in zip(d_loss_real_array, d_loss_fake_array)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:31.929463Z",
     "iopub.status.busy": "2022-08-22T12:01:31.928697Z",
     "iopub.status.idle": "2022-08-22T12:01:31.934446Z",
     "shell.execute_reply": "2022-08-22T12:01:31.933352Z",
     "shell.execute_reply.started": "2022-08-22T12:01:31.929416Z"
    },
    "id": "oMK7DxoPuGxL"
   },
   "outputs": [],
   "source": [
    "g_loss = g_loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:32.728193Z",
     "iopub.status.busy": "2022-08-22T12:01:32.727289Z",
     "iopub.status.idle": "2022-08-22T12:01:33.035418Z",
     "shell.execute_reply": "2022-08-22T12:01:33.034495Z",
     "shell.execute_reply.started": "2022-08-22T12:01:32.728144Z"
    },
    "id": "s5qYW8JZxlWt",
    "outputId": "35e88c8c-5006-45f9-e9f5-995f5480fdee"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(d_loss)\n",
    "plt.title('Discriminator Loss Graph')\n",
    "plt.ylabel('Discriminator Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Discriminator Loss\"], loc='upper right')\n",
    "plt.savefig(\"Discriminator_Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:35.989613Z",
     "iopub.status.busy": "2022-08-22T12:01:35.988911Z",
     "iopub.status.idle": "2022-08-22T12:01:36.283356Z",
     "shell.execute_reply": "2022-08-22T12:01:36.282422Z",
     "shell.execute_reply.started": "2022-08-22T12:01:35.989576Z"
    },
    "id": "Kla0HPDNymA1",
    "outputId": "c6dbad51-f25d-4bec-d6e2-6460ca061b2c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(g_loss,color='orange')\n",
    "plt.title('Generator Loss Graph')\n",
    "plt.ylabel('Generator Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Generator Loss\"], loc='upper right')\n",
    "plt.savefig(\"Generator_Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T12:01:39.333047Z",
     "iopub.status.busy": "2022-08-22T12:01:39.331944Z",
     "iopub.status.idle": "2022-08-22T12:01:39.630592Z",
     "shell.execute_reply": "2022-08-22T12:01:39.629555Z",
     "shell.execute_reply.started": "2022-08-22T12:01:39.333000Z"
    },
    "id": "Eaf2HX2i0MV3",
    "outputId": "ec1cf3fc-8ddc-494e-9799-443713645c36"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(d_loss)\n",
    "plt.plot(g_loss)\n",
    "plt.title('Loss Graph')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Discriminator Loss\", \"Generator Loss\"], loc='lower right')\n",
    "plt.savefig(\"Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzogkr9dAr6c"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T11:38:53.356753Z",
     "iopub.status.busy": "2022-08-22T11:38:53.354903Z",
     "iopub.status.idle": "2022-08-22T11:38:53.361370Z",
     "shell.execute_reply": "2022-08-22T11:38:53.360398Z",
     "shell.execute_reply.started": "2022-08-22T11:38:53.356713Z"
    },
    "id": "SGdHt4FStkL5",
    "outputId": "5eec7c6e-1744-4f85-8cd0-d1b05a3e18c0"
   },
   "outputs": [],
   "source": [
    "generator = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/GAN_New_Approch/LSGAN/generator_model_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T11:38:53.364117Z",
     "iopub.status.busy": "2022-08-22T11:38:53.362896Z",
     "iopub.status.idle": "2022-08-22T11:38:53.373017Z",
     "shell.execute_reply": "2022-08-22T11:38:53.371796Z",
     "shell.execute_reply.started": "2022-08-22T11:38:53.364087Z"
    },
    "id": "3gsO4c2O7iCX",
    "outputId": "eb0c0a2f-3a37-44be-a8f6-aa495683a076"
   },
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "n_samples = 16\n",
    "z_input, labels = generate_latent_points(latent_dim, n_samples)\n",
    "data = [z_input,labels]\n",
    "pred = generator.predict(data)\n",
    "pred = (pred + 1 ) / 2.0\n",
    "save_plot(pred,n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpQNj8x8IsM"
   },
   "source": [
    "                                              -:END:-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
